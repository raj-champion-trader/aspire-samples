#!/usr/bin/env python3
"""
Oracle SQL Code Complexity Analyzer
===================================

A comprehensive tool to analyze Oracle SQL codebases and generate complexity metrics,
effort estimates, and risk assessments for migration planning.

Author: Generated by Claude
Version: 1.0.0
"""

import os
import re
import json
import yaml
import pandas as pd
from pathlib import Path
from dataclasses import dataclass, asdict, field
from typing import List, Dict, Set, Optional, Tuple
import argparse
import logging
from datetime import datetime
from tqdm import tqdm
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.offline as pyo
from colorama import init, Fore, Style

# Initialize colorama for colored output
init()

@dataclass
class SQLMetrics:
    """Data class to store SQL metrics for a single file"""
    file_path: str
    file_name: str
    file_type: str
    total_lines: int
    code_lines: int
    comment_lines: int
    blank_lines: int
    cyclomatic_complexity: int
    max_nesting_depth: int
    procedure_count: int
    function_count: int
    trigger_count: int
    package_count: int
    cursor_count: int
    exception_handlers: int
    dml_statements: List[str] = field(default_factory=list)
    ddl_statements: List[str] = field(default_factory=list)
    oracle_features: List[str] = field(default_factory=list)
    database_objects: Dict[str, List[str]] = field(default_factory=dict)
    external_references: List[str] = field(default_factory=list)
    deprecated_features: List[str] = field(default_factory=list)
    performance_issues: List[str] = field(default_factory=list)
    complexity_score: float = 0.0
    estimated_effort_hours: float = 0.0
    risk_level: str = "Medium"
    risk_score: float = 0.0
    file_size_kb: float = 0.0
    last_modified: str = ""

class OracleSQLAnalyzer:
    """Main analyzer class for Oracle SQL code complexity analysis"""

    def __init__(self, config_path: str = "sql_config.yaml"):
        """Initialize the analyzer with configuration"""
        self.config = self._load_config(config_path)
        self.metrics: List[SQLMetrics] = []
        self.summary_stats = {}
        self.logger = self._setup_logging()

    def _load_config(self, config_path: str) -> dict:
        """Load configuration from YAML file"""
        try:
            with open(config_path, 'r') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            self.logger.warning(f"Config file {config_path} not found. Using defaults.")
            return self._get_default_config()

    def _get_default_config(self) -> dict:
        """Return default configuration if config file is not found"""
        return {
            'complexity_thresholds': {
                'cyclomatic': {'low': 10, 'medium': 25, 'high': 50},
                'nesting': {'low': 3, 'medium': 6, 'high': 10},
                'file_size': {'small': 200, 'medium': 500, 'large': 1000}
            },
            'effort_factors': {
                'base_loc_per_hour': 30,
                'procedure_weight': 2.0,
                'function_weight': 1.8,
                'trigger_weight': 3.0,
                'package_weight': 2.5,
                'cursor_weight': 1.5,
                'oracle_feature_weight': 2.0,
                'deprecated_weight': 3.0,
                'performance_issue_weight': 2.5
            },
            'file_patterns': ['*.sql', '*.pks', '*.pkb', '*.prc', '*.fnc', '*.trg', '*.typ', '*.tps', '*.tpb'],
            'oracle_features': [
                'CONNECT BY', 'START WITH', 'PRIOR', 'LEVEL',
                'ROWNUM', 'ROWID', 'DUAL',
                'DECODE', 'NVL', 'NVL2', 'NULLIF', 'COALESCE',
                'REGEXP_LIKE', 'REGEXP_REPLACE', 'REGEXP_SUBSTR',
                'XMLTYPE', 'XMLQUERY', 'XMLTABLE',
                'MERGE', 'UPSERT',
                'PARTITION BY', 'OVER', 'RANK', 'DENSE_RANK', 'ROW_NUMBER',
                'LISTAGG', 'PIVOT', 'UNPIVOT',
                'FLASHBACK', 'AS OF TIMESTAMP',
                'DBMS_', 'UTL_', 'APEX_'
            ],
            'deprecated_features': [
                'LONG', 'LONG RAW',
                'CONNECT BY NOCYCLE',
                'GOTO',
                'SQLCODE', 'SQLERRM',
                'DBMS_SQL',
                'WHEN OTHERS THEN NULL'
            ],
            'performance_issues': [
                'SELECT \*', 'NOT IN', 'OR',
                'DISTINCT', 'ORDER BY.*ROWNUM',
                'SUBSTR.*LIKE', 'UPPER.*LIKE', 'LOWER.*LIKE',
                'TO_CHAR.*DATE', 'TO_DATE.*VARCHAR',
                'NESTED LOOP', 'CARTESIAN'
            ]
        }

    def _setup_logging(self) -> logging.Logger:
        """Setup logging configuration"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('oracle_sql_analyzer.log'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)

    def scan_directory(self, root_path: str, recursive: bool = True) -> None:
        """Scan directory for Oracle SQL files and analyze them"""
        root = Path(root_path)
        if not root.exists():
            raise FileNotFoundError(f"Directory {root_path} does not exist")

        self.logger.info(f"Scanning directory: {root_path}")

        # Find all SQL files
        sql_files = []
        patterns = self.config.get('file_patterns', ['*.sql', '*.pks', '*.pkb'])

        for pattern in patterns:
            if recursive:
                sql_files.extend(root.rglob(pattern))
            else:
                sql_files.extend(root.glob(pattern))

        self.logger.info(f"Found {len(sql_files)} SQL files")

        # Analyze each file with progress bar
        for file_path in tqdm(sql_files, desc="Analyzing files"):
            try:
                metrics = self._analyze_file(file_path)
                self.metrics.append(metrics)
            except Exception as e:
                self.logger.error(f"Error analyzing {file_path}: {str(e)}")

        self._calculate_summary_stats()
        self.logger.info(f"Analysis complete. Processed {len(self.metrics)} files")

    def _analyze_file(self, file_path: Path) -> SQLMetrics:
        """Analyze a single SQL file"""
        try:
            # Try different encodings
            content = ""
            for encoding in ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    break
                except UnicodeDecodeError:
                    continue

            if not content:
                raise ValueError(f"Could not decode file {file_path}")

            # Normalize content - remove string literals and comments for analysis
            normalized_content = self._normalize_sql_content(content)
            lines = content.split('\n')
            file_stats = file_path.stat()

            metrics = SQLMetrics(
                file_path=str(file_path),
                file_name=file_path.name,
                file_type=file_path.suffix,
                total_lines=len(lines),
                code_lines=self._count_code_lines(lines),
                comment_lines=self._count_comment_lines(lines),
                blank_lines=self._count_blank_lines(lines),
                cyclomatic_complexity=self._calculate_cyclomatic_complexity(normalized_content),
                max_nesting_depth=self._calculate_max_nesting_depth(normalized_content),
                procedure_count=self._count_procedures(normalized_content),
                function_count=self._count_functions(normalized_content),
                trigger_count=self._count_triggers(normalized_content),
                package_count=self._count_packages(normalized_content),
                cursor_count=self._count_cursors(normalized_content),
                exception_handlers=self._count_exception_handlers(normalized_content),
                dml_statements=self._extract_dml_statements(normalized_content),
                ddl_statements=self._extract_ddl_statements(normalized_content),
                oracle_features=self._find_oracle_features(normalized_content),
                database_objects=self._extract_database_objects(normalized_content),
                external_references=self._extract_external_references(normalized_content),
                deprecated_features=self._find_deprecated_features(normalized_content),
                performance_issues=self._find_performance_issues(normalized_content),
                file_size_kb=file_stats.st_size / 1024,
                last_modified=datetime.fromtimestamp(file_stats.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
            )

            # Calculate derived metrics
            metrics.complexity_score = self._calculate_complexity_score(metrics)
            metrics.estimated_effort_hours = self._estimate_effort(metrics)
            metrics.risk_score = self._calculate_risk_score(metrics)
            metrics.risk_level = self._assess_risk_level(metrics.risk_score)

            return metrics

        except Exception as e:
            self.logger.error(f"Error analyzing file {file_path}: {str(e)}")
            raise

    def _normalize_sql_content(self, content: str) -> str:
        """Normalize SQL content by removing string literals and comments"""
        # Remove single-line comments
        content = re.sub(r'--.*$', '', content, flags=re.MULTILINE)

        # Remove multi-line comments
        content = re.sub(r'/\*.*?\*/', '', content, flags=re.DOTALL)

        # Remove string literals (simplified - doesn't handle all edge cases)
        content = re.sub(r"'[^']*'", "''", content)
        content = re.sub(r'"[^"]*"', '""', content)

        return content.upper()

    def _count_code_lines(self, lines: List[str]) -> int:
        """Count non-comment, non-blank lines"""
        code_lines = 0
        for line in lines:
            stripped = line.strip()
            if stripped and not stripped.startswith("--") and not stripped.startswith("/*"):
                code_lines += 1
        return code_lines

    def _count_comment_lines(self, lines: List[str]) -> int:
        """Count comment lines"""
        comment_lines = 0
        in_multiline_comment = False

        for line in lines:
            stripped = line.strip()

            if '/*' in stripped:
                in_multiline_comment = True
                comment_lines += 1
            elif '*/' in stripped:
                in_multiline_comment = False
                if not stripped.startswith('*/'):
                    comment_lines += 1
            elif in_multiline_comment:
                comment_lines += 1
            elif stripped.startswith("--"):
                comment_lines += 1

        return comment_lines

    def _count_blank_lines(self, lines: List[str]) -> int:
        """Count blank lines"""
        return sum(1 for line in lines if not line.strip())

    def _calculate_cyclomatic_complexity(self, content: str) -> int:
        """Calculate cyclomatic complexity for SQL"""
        complexity = 1  # Base complexity

        # Decision points that increase complexity
        decision_patterns = [
            r'\bIF\b',  # IF statements
            r'\bELSIF\b',  # ELSIF
            r'\bELSE\b',  # ELSE
            r'\bCASE\b',  # CASE statements
            r'\bWHEN\b',  # WHEN clauses
            r'\bWHILE\b',  # WHILE loops
            r'\bFOR\b',  # FOR loops
            r'\bLOOP\b',  # LOOP statements
            r'\bAND\b',  # Logical AND
            r'\bOR\b',  # Logical OR
            r'\bEXCEPTION\b',  # Exception handling
            r'\bWHERE\b',  # WHERE clauses
            r'\bHAVING\b',  # HAVING clauses
            r'\bJOIN\b',  # JOIN operations
            r'\bUNION\b',  # UNION operations
            r'\bEXISTS\b',  # EXISTS clauses
            r'\bIN\s*\(',  # IN clauses
        ]

        for pattern in decision_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE | re.MULTILINE)
            complexity += len(matches)

        return complexity

    def _calculate_max_nesting_depth(self, content: str) -> int:
        """Calculate maximum nesting depth"""
        lines = content.split('\n')
        max_depth = 0
        current_depth = 0

        for line in lines:
            stripped = line.strip()

            # Increase depth
            if any(keyword in stripped for keyword in [
                'IF ', 'FOR ', 'WHILE ', 'LOOP', 'BEGIN', 'CASE',
                'DECLARE', 'PROCEDURE', 'FUNCTION'
            ]):
                current_depth += 1
                max_depth = max(max_depth, current_depth)

            # Decrease depth
            elif any(keyword in stripped for keyword in [
                'END IF', 'END LOOP', 'END CASE', 'END;', 'END ', '/'
            ]):
                current_depth = max(0, current_depth - 1)

        return max_depth

    def _count_procedures(self, content: str) -> int:
        """Count stored procedures"""
        procedure_pattern = r'\b(CREATE\s+OR\s+REPLACE\s+)?PROCEDURE\s+\w+'
        return len(re.findall(procedure_pattern, content, re.IGNORECASE))

    def _count_functions(self, content: str) -> int:
        """Count functions"""
        function_pattern = r'\b(CREATE\s+OR\s+REPLACE\s+)?FUNCTION\s+\w+'
        return len(re.findall(function_pattern, content, re.IGNORECASE))

    def _count_triggers(self, content: str) -> int:
        """Count triggers"""
        trigger_pattern = r'\b(CREATE\s+OR\s+REPLACE\s+)?TRIGGER\s+\w+'
        return len(re.findall(trigger_pattern, content, re.IGNORECASE))

    def _count_packages(self, content: str) -> int:
        """Count packages"""
        package_pattern = r'\b(CREATE\s+OR\s+REPLACE\s+)?PACKAGE\s+(BODY\s+)?\w+'
        return len(re.findall(package_pattern, content, re.IGNORECASE))

    def _count_cursors(self, content: str) -> int:
        """Count cursor declarations"""
        cursor_patterns = [
            r'\bCURSOR\s+\w+',
            r'\bFOR\s+\w+\s+IN\s*\(',
            r'\bOPEN\s+\w+',
            r'\bFETCH\s+\w+'
        ]

        count = 0
        for pattern in cursor_patterns:
            count += len(re.findall(pattern, content, re.IGNORECASE))

        return count

    def _count_exception_handlers(self, content: str) -> int:
        """Count exception handlers"""
        exception_patterns = [
            r'\bEXCEPTION\b',
            r'\bWHEN\s+\w+\s+THEN',
            r'\bWHEN\s+OTHERS\s+THEN',
            r'\bRAISE\b',
            r'\bRAISE_APPLICATION_ERROR\b'
        ]

        count = 0
        for pattern in exception_patterns:
            count += len(re.findall(pattern, content, re.IGNORECASE))

        return count

    def _extract_dml_statements(self, content: str) -> List[str]:
        """Extract DML statements"""
        dml_statements = []
        dml_patterns = [
            r'\bSELECT\b.*?(?=;|$|\bFROM\b)',
            r'\bINSERT\s+INTO\s+\w+',
            r'\bUPDATE\s+\w+',
            r'\bDELETE\s+FROM\s+\w+',
            r'\bMERGE\s+INTO\s+\w+'
        ]

        for pattern in dml_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
            dml_statements.extend([match.strip()[:100] + '...' if len(match) > 100 else match.strip() 
                                 for match in matches])

        return list(set(dml_statements))  # Remove duplicates

    def _extract_ddl_statements(self, content: str) -> List[str]:
        """Extract DDL statements"""
        ddl_statements = []
        ddl_patterns = [
            r'\bCREATE\s+(TABLE|INDEX|VIEW|SEQUENCE|SYNONYM)\s+\w+',
            r'\bALTER\s+(TABLE|INDEX|VIEW)\s+\w+',
            r'\bDROP\s+(TABLE|INDEX|VIEW|SEQUENCE|SYNONYM)\s+\w+',
            r'\bTRUNCATE\s+TABLE\s+\w+'
        ]

        for pattern in ddl_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            ddl_statements.extend(matches)

        return list(set(ddl_statements))

    def _find_oracle_features(self, content: str) -> List[str]:
        """Find Oracle-specific features"""
        oracle_features = []
        features = self.config.get('oracle_features', [])

        for feature in features:
            if re.search(rf'\b{re.escape(feature)}\b', content, re.IGNORECASE):
                oracle_features.append(feature)

        return oracle_features

    def _extract_database_objects(self, content: str) -> Dict[str, List[str]]:
        """Extract database objects (tables, views, etc.)"""
        db_objects = {
            'tables': [],
            'views': [],
            'sequences': [],
            'indexes': [],
            'synonyms': [],
            'packages': [],
            'procedures': [],
            'functions': []
        }

        # Table references
        table_patterns = [
            r'FROM\s+(\w+(?:\.\w+)?)',
            r'JOIN\s+(\w+(?:\.\w+)?)',
            r'INSERT\s+INTO\s+(\w+(?:\.\w+)?)',
            r'UPDATE\s+(\w+(?:\.\w+)?)',
            r'DELETE\s+FROM\s+(\w+(?:\.\w+)?)'
        ]

        for pattern in table_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            db_objects['tables'].extend(matches)

        # Other object types
        object_patterns = {
            'views': [r'CREATE\s+VIEW\s+(\w+)'],
            'sequences': [r'(\w+)\.NEXTVAL', r'(\w+)\.CURRVAL', r'CREATE\s+SEQUENCE\s+(\w+)'],
            'indexes': [r'CREATE\s+INDEX\s+(\w+)'],
            'synonyms': [r'CREATE\s+SYNONYM\s+(\w+)'],
            'packages': [r'(\w+)\.(\w+)\s*\('],
            'procedures': [r'EXEC\s+(\w+(?:\.\w+)?)'],
            'functions': [r'(\w+)\s*\([^)]*\)\s*(?=FROM|WHERE|AND|OR|,|;)']
        }

        for obj_type, patterns in object_patterns.items():
            for pattern in patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                if obj_type == 'packages':
                    # For packages, combine schema.package format
                    db_objects[obj_type].extend([f"{m[0]}.{m[1]}" for m in matches if isinstance(m, tuple)])
                else:
                    db_objects[obj_type].extend([m if isinstance(m, str) else m[0] for m in matches])

        # Remove duplicates and clean up
        for key in db_objects:
            db_objects[key] = list(set([obj.upper() for obj in db_objects[key] if obj and not obj.isdigit()]))

        return db_objects

    def _extract_external_references(self, content: str) -> List[str]:
        """Extract external references (database links, external tables, etc.)"""
        external_refs = []

        # Database links
        dblink_pattern = r'@(\w+)'
        dblinks = re.findall(dblink_pattern, content, re.IGNORECASE)
        external_refs.extend([f"@{link}" for link in dblinks])

        # External tables
        external_table_pattern = r'EXTERNAL\s+TABLE\s+(\w+)'
        external_tables = re.findall(external_table_pattern, content, re.IGNORECASE)
        external_refs.extend([f"EXTERNAL_TABLE:{table}" for table in external_tables])

        # UTL_FILE references
        if re.search(r'UTL_FILE', content, re.IGNORECASE):
            external_refs.append("UTL_FILE")

        # DBMS_SCHEDULER references
        if re.search(r'DBMS_SCHEDULER', content, re.IGNORECASE):
            external_refs.append("DBMS_SCHEDULER")

        return list(set(external_refs))

    def _find_deprecated_features(self, content: str) -> List[str]:
        """Find deprecated Oracle features"""
        deprecated_features = []
        features = self.config.get('deprecated_features', [])

        for feature in features:
            if re.search(rf'\b{re.escape(feature)}\b', content, re.IGNORECASE):
                deprecated_features.append(feature)

        return deprecated_features

    def _find_performance_issues(self, content: str) -> List[str]:
        """Find potential performance issues"""
        performance_issues = []
        issues = self.config.get('performance_issues', [])

        for issue in issues:
            if re.search(issue, content, re.IGNORECASE):
                performance_issues.append(issue)

        return performance_issues

    def _calculate_complexity_score(self, metrics: SQLMetrics) -> float:
        """Calculate overall complexity score"""
        # Normalize different metrics to 0-1 scale
        cyclomatic_norm = min(metrics.cyclomatic_complexity / 50, 1.0)
        nesting_norm = min(metrics.max_nesting_depth / 10, 1.0)
        size_norm = min(metrics.code_lines / 1000, 1.0)

        # Object complexity
        object_count = (metrics.procedure_count + metrics.function_count + 
                       metrics.trigger_count + metrics.package_count)
        object_norm = min(object_count / 10, 1.0)

        # Feature complexity
        feature_norm = min(len(metrics.oracle_features) / 20, 1.0)
        deprecated_norm = min(len(metrics.deprecated_features) / 5, 1.0)
        performance_norm = min(len(metrics.performance_issues) / 10, 1.0)

        # Weight different factors
        complexity_score = (
            cyclomatic_norm * 0.25 +
            nesting_norm * 0.20 +
            size_norm * 0.15 +
            object_norm * 0.15 +
            feature_norm * 0.10 +
            deprecated_norm * 0.10 +
            performance_norm * 0.05
        )

        return round(complexity_score * 100, 2)  # Scale to 0-100

    def _estimate_effort(self, metrics: SQLMetrics) -> float:
        """Estimate development effort in hours"""
        factors = self.config.get('effort_factors', {})
        base_rate = factors.get('base_loc_per_hour', 30)

        # Base effort from lines of code
        base_effort = metrics.code_lines / base_rate

        # Apply complexity multipliers
        complexity_multiplier = 1 + (metrics.cyclomatic_complexity / 100)
        nesting_multiplier = 1 + (metrics.max_nesting_depth / 20)

        # Object type multipliers
        procedure_multiplier = 1 + (metrics.procedure_count * factors.get('procedure_weight', 2.0) / 100)
        function_multiplier = 1 + (metrics.function_count * factors.get('function_weight', 1.8) / 100)
        trigger_multiplier = 1 + (metrics.trigger_count * factors.get('trigger_weight', 3.0) / 100)
        package_multiplier = 1 + (metrics.package_count * factors.get('package_weight', 2.5) / 100)

        # Feature complexity
        oracle_feature_multiplier = 1 + (len(metrics.oracle_features) * factors.get('oracle_feature_weight', 2.0) / 100)
        deprecated_multiplier = 1 + (len(metrics.deprecated_features) * factors.get('deprecated_weight', 3.0) / 100)
        performance_multiplier = 1 + (len(metrics.performance_issues) * factors.get('performance_issue_weight', 2.5) / 100)

        # Database object complexity
        db_object_count = sum(len(objects) for objects in metrics.database_objects.values())
        db_multiplier = 1 + (db_object_count / 100)

        total_effort = (base_effort * complexity_multiplier * nesting_multiplier * 
                       procedure_multiplier * function_multiplier * trigger_multiplier *
                       package_multiplier * oracle_feature_multiplier * deprecated_multiplier *
                       performance_multiplier * db_multiplier)

        return round(total_effort, 2)

    def _calculate_risk_score(self, metrics: SQLMetrics) -> float:
        """Calculate risk score for migration"""
        weights = self.config.get('risk_weights', {
            'complexity': 0.25,
            'oracle_features': 0.20,
            'deprecated_features': 0.20,
            'performance_issues': 0.15,
            'database_dependencies': 0.10,
            'code_size': 0.10
        })

        # Normalize metrics to 0-1 scale
        complexity_risk = min(metrics.cyclomatic_complexity / 50, 1.0)
        oracle_feature_risk = min(len(metrics.oracle_features) / 20, 1.0)
        deprecated_risk = min(len(metrics.deprecated_features) / 5, 1.0)
        performance_risk = min(len(metrics.performance_issues) / 10, 1.0)

        db_object_count = sum(len(objects) for objects in metrics.database_objects.values())
        db_risk = min(db_object_count / 20, 1.0)

        size_risk = min(metrics.code_lines / 1000, 1.0)

        risk_score = (
            complexity_risk * weights['complexity'] +
            oracle_feature_risk * weights['oracle_features'] +
            deprecated_risk * weights['deprecated_features'] +
            performance_risk * weights['performance_issues'] +
            db_risk * weights['database_dependencies'] +
            size_risk * weights['code_size']
        )

        return round(risk_score * 100, 2)

    def _assess_risk_level(self, risk_score: float) -> str:
        """Assess risk level based on risk score"""
        if risk_score >= 70:
            return "High"
        elif risk_score >= 40:
            return "Medium"
        else:
            return "Low"

    def _calculate_summary_stats(self) -> None:
        """Calculate summary statistics"""
        if not self.metrics:
            return

        df = pd.DataFrame([asdict(m) for m in self.metrics])

        self.summary_stats = {
            'total_files': len(self.metrics),
            'total_lines': df['total_lines'].sum(),
            'total_code_lines': df['code_lines'].sum(),
            'total_estimated_hours': df['estimated_effort_hours'].sum(),
            'average_complexity': df['cyclomatic_complexity'].mean(),
            'high_risk_files': len(df[df['risk_level'] == 'High']),
            'medium_risk_files': len(df[df['risk_level'] == 'Medium']),
            'low_risk_files': len(df[df['risk_level'] == 'Low']),
            'file_types': df['file_type'].value_counts().to_dict(),
            'total_procedures': df['procedure_count'].sum(),
            'total_functions': df['function_count'].sum(),
            'total_triggers': df['trigger_count'].sum(),
            'total_packages': df['package_count'].sum(),
            'most_complex_file': df.loc[df['cyclomatic_complexity'].idxmax(), 'file_name'],
            'largest_file': df.loc[df['code_lines'].idxmax(), 'file_name'],
            'highest_effort_file': df.loc[df['estimated_effort_hours'].idxmax(), 'file_name']
        }

    def generate_html_report(self, output_file: str = "oracle_sql_complexity_report.html") -> str:
        """Generate comprehensive HTML report"""
        if not self.metrics:
            raise ValueError("No metrics available. Run scan_directory first.")

        df = pd.DataFrame([asdict(m) for m in self.metrics])

        # Create visualizations
        charts_html = self._create_charts(df)

        html_template = """
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Oracle SQL Code Complexity Analysis Report</title>
    <link href="https://cdn.datatables.net/1.11.5/css/jquery.dataTables.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <script src="https://cdn.datatables.net/1.11.5/js/jquery.dataTables.min.js"></script>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <style>
        body {{ 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            margin: 0; 
            padding: 20px; 
            background-color: #f5f5f5;
        }}
        .container {{ max-width: 1400px; margin: 0 auto; }}
        h1 {{ 
            color: #2c3e50; 
            text-align: center; 
            margin-bottom: 30px;
            font-size: 2.5em;
        }}
        h2 {{ 
            color: #34495e; 
            border-bottom: 2px solid #e74c3c;
            padding-bottom: 10px;
        }}
        .summary {{ 
            background: white; 
            padding: 25px; 
            margin: 20px 0; 
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .summary-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }}
        .summary-card {{
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            text-align: center;
            border-left: 4px solid #e74c3c;
        }}
        .summary-card h3 {{
            margin: 0 0 10px 0;
            color: #2c3e50;
            font-size: 1.2em;
        }}
        .summary-card .value {{
            font-size: 2em;
            font-weight: bold;
            color: #e74c3c;
        }}
        .filters {{ 
            background: white;
            padding: 20px; 
            margin: 20px 0; 
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .filter-group {{ 
            display: inline-block; 
            margin-right: 20px; 
            margin-bottom: 10px;
        }}
        .filter-group label {{
            font-weight: bold;
            color: #2c3e50;
        }}
        .filter-group select, .filter-group input {{
            margin-left: 10px;
            padding: 5px 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
        }}
        .high-risk {{ background-color: #ffebee !important; }}
        .medium-risk {{ background-color: #fff3e0 !important; }}
        .low-risk {{ background-color: #e8f5e8 !important; }}
        .charts-section {{
            background: white;
            padding: 25px;
            margin: 20px 0;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .chart-container {{
            margin: 30px 0;
            min-height: 400px;
        }}
        table.dataTable {{
            background: white;
            border-radius: 10px;
            overflow: hidden;
        }}
        table.dataTable thead th {{
            background-color: #e74c3c;
            color: white;
            font-weight: bold;
        }}
        .risk-high {{ color: #e74c3c; font-weight: bold; }}
        .risk-medium {{ color: #f39c12; font-weight: bold; }}
        .risk-low {{ color: #27ae60; font-weight: bold; }}
        .footer {{
            text-align: center;
            margin-top: 40px;
            padding: 20px;
            color: #7f8c8d;
            border-top: 1px solid #ecf0f1;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1><i class="fas fa-database"></i> Oracle SQL Code Complexity Analysis Report</h1>
        <p style="text-align: center; color: #7f8c8d; font-size: 1.1em;">
            Generated on {timestamp}
        </p>

        <div class="summary">
            <h2><i class="fas fa-chart-bar"></i> Executive Summary</h2>
            <div class="summary-grid">
                <div class="summary-card">
                    <h3>Total Files</h3>
                    <div class="value">{total_files}</div>
                </div>
                <div class="summary-card">
                    <h3>Lines of Code</h3>
                    <div class="value">{total_code_lines:,}</div>
                </div>
                <div class="summary-card">
                    <h3>Estimated Effort</h3>
                    <div class="value">{total_effort:.0f}h</div>
                </div>
                <div class="summary-card">
                    <h3>High Risk Files</h3>
                    <div class="value" style="color: #e74c3c;">{high_risk_count}</div>
                </div>
                <div class="summary-card">
                    <h3>Procedures</h3>
                    <div class="value">{total_procedures}</div>
                </div>
                <div class="summary-card">
                    <h3>Functions</h3>
                    <div class="value">{total_functions}</div>
                </div>
                <div class="summary-card">
                    <h3>Triggers</h3>
                    <div class="value">{total_triggers}</div>
                </div>
                <div class="summary-card">
                    <h3>Packages</h3>
                    <div class="value">{total_packages}</div>
                </div>
            </div>
        </div>

        <div class="charts-section">
            <h2><i class="fas fa-chart-pie"></i> Visual Analysis</h2>
            {charts_html}
        </div>

        <div class="filters">
            <h2><i class="fas fa-filter"></i> Filters</h2>
            <div class="filter-group">
                <label><i class="fas fa-exclamation-triangle"></i> Risk Level: 
                    <select id="riskFilter">
                        <option value="">All</option>
                        <option value="High">High</option>
                        <option value="Medium">Medium</option>
                        <option value="Low">Low</option>
                    </select>
                </label>
            </div>
            <div class="filter-group">
                <label><i class="fas fa-file-code"></i> File Type: 
                    <select id="typeFilter">
                        <option value="">All</option>
                        <option value=".sql">SQL (.sql)</option>
                        <option value=".pks">Package Spec (.pks)</option>
                        <option value=".pkb">Package Body (.pkb)</option>
                        <option value=".prc">Procedure (.prc)</option>
                        <option value=".fnc">Function (.fnc)</option>
                        <option value=".trg">Trigger (.trg)</option>
                    </select>
                </label>
            </div>
            <div class="filter-group">
                <label><i class="fas fa-cogs"></i> Min Complexity: 
                    <input type="number" id="complexityFilter" min="0" value="0" style="width: 80px;">
                </label>
            </div>
            <div class="filter-group">
                <label><i class="fas fa-clock"></i> Min Effort (hours): 
                    <input type="number" id="effortFilter" min="0" value="0" step="0.1" style="width: 80px;">
                </label>
            </div>
        </div>

        <div style="background: white; padding: 25px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
            <h2><i class="fas fa-table"></i> Detailed Analysis</h2>
            <table id="metricsTable" class="display" style="width:100%">
                <thead>
                    <tr>
                        <th>File Name</th>
                        <th>Type</th>
                        <th>LOC</th>
                        <th>Complexity</th>
                        <th>Procedures</th>
                        <th>Functions</th>
                        <th>Triggers</th>
                        <th>Oracle Features</th>
                        <th>Deprecated</th>
                        <th>Est. Hours</th>
                        <th>Risk Level</th>
                        <th>Risk Score</th>
                    </tr>
                </thead>
                <tbody>
                    {table_rows}
                </tbody>
            </table>
        </div>

        <div class="footer">
            <p>Oracle SQL Code Complexity Analyzer v1.0.0 | Generated by Claude AI Assistant</p>
        </div>
    </div>

    <script>
        $(document).ready(function() {{
            var table = $('#metricsTable').DataTable({{
                pageLength: 25,
                order: [[9, 'desc']], // Sort by estimated hours
                columnDefs: [
                    {{
                        targets: [10], // Risk Level column
                        render: function(data, type, row) {{
                            var className = 'risk-' + data.toLowerCase();
                            return '<span class="' + className + '">' + data + '</span>';
                        }}
                    }}
                ]
            }});

            // Filter functionality
            $('#riskFilter, #typeFilter').on('change', function() {{
                table.draw();
            }});

            $('#complexityFilter, #effortFilter').on('keyup change', function() {{
                table.draw();
            }});

            // Custom search function
            $.fn.dataTable.ext.search.push(
                function(settings, data, dataIndex) {{
                    var risk = $('#riskFilter').val();
                    var type = $('#typeFilter').val();
                    var minComplexity = parseInt($('#complexityFilter').val()) || 0;
                    var minEffort = parseFloat($('#effortFilter').val()) || 0;

                    if (risk && data[10] !== risk) return false;
                    if (type && data[1] !== type) return false;
                    if (parseInt(data[3]) < minComplexity) return false;
                    if (parseFloat(data[9]) < minEffort) return false;

                    return true;
                }}
            );
        }});
    </script>
</body>
</html>
        """

        # Generate table rows
        table_rows = ""
        for _, row in df.iterrows():
            risk_class = f"{row['risk_level'].lower()}-risk"
            oracle_features_count = len(row['oracle_features']) if isinstance(row['oracle_features'], list) else 0
            deprecated_count = len(row['deprecated_features']) if isinstance(row['deprecated_features'], list) else 0

            table_rows += f"""
                <tr class="{risk_class}">
                    <td title="{row['file_path']}">{row['file_name']}</td>
                    <td>{row['file_type']}</td>
                    <td>{row['code_lines']}</td>
                    <td>{row['cyclomatic_complexity']}</td>
                    <td>{row['procedure_count']}</td>
                    <td>{row['function_count']}</td>
                    <td>{row['trigger_count']}</td>
                    <td>{oracle_features_count}</td>
                    <td>{deprecated_count}</td>
                    <td>{row['estimated_effort_hours']:.1f}</td>
                    <td>{row['risk_level']}</td>
                    <td>{row['risk_score']:.1f}</td>
                </tr>
            """

        # Format the HTML
        html_content = html_template.format(
            timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            table_rows=table_rows,
            charts_html=charts_html,
            total_files=self.summary_stats['total_files'],
            total_code_lines=self.summary_stats['total_code_lines'],
            total_effort=self.summary_stats['total_estimated_hours'],
            high_risk_count=self.summary_stats['high_risk_files'],
            total_procedures=self.summary_stats['total_procedures'],
            total_functions=self.summary_stats['total_functions'],
            total_triggers=self.summary_stats['total_triggers'],
            total_packages=self.summary_stats['total_packages']
        )

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html_content)

        self.logger.info(f"HTML report generated: {output_file}")
        return output_file

    def _create_charts(self, df: pd.DataFrame) -> str:
        """Create interactive charts for the report"""
        charts_html = ""

        # 1. Risk Distribution Pie Chart
        risk_counts = df['risk_level'].value_counts()
        fig1 = px.pie(
            values=risk_counts.values, 
            names=risk_counts.index,
            title="Risk Level Distribution",
            color_discrete_map={'High': '#e74c3c', 'Medium': '#f39c12', 'Low': '#27ae60'}
        )
        fig1.update_layout(height=400)
        charts_html += f'<div class="chart-container" id="risk-chart">{fig1.to_html(include_plotlyjs=False, div_id="risk-chart")}</div>'

        # 2. Complexity vs Effort Scatter Plot
        fig2 = px.scatter(
            df, 
            x='cyclomatic_complexity', 
            y='estimated_effort_hours',
            color='risk_level',
            size='code_lines',
            hover_data=['file_name'],
            title="Complexity vs Estimated Effort",
            color_discrete_map={'High': '#e74c3c', 'Medium': '#f39c12', 'Low': '#27ae60'}
        )
        fig2.update_layout(height=400)
        charts_html += f'<div class="chart-container" id="scatter-chart">{fig2.to_html(include_plotlyjs=False, div_id="scatter-chart")}</div>'

        # 3. File Type Distribution
        file_type_counts = df['file_type'].value_counts()
        fig3 = px.bar(
            x=file_type_counts.index,
            y=file_type_counts.values,
            title="Files by Type",
            labels={'x': 'File Type', 'y': 'Count'}
        )
        fig3.update_layout(height=400)
        charts_html += f'<div class="chart-container" id="filetype-chart">{fig3.to_html(include_plotlyjs=False, div_id="filetype-chart")}</div>'

        # 4. Database Object Types
        db_object_data = []
        for _, row in df.iterrows():
            if isinstance(row['database_objects'], dict):
                for obj_type, objects in row['database_objects'].items():
                    if isinstance(objects, list):
                        db_object_data.append({'type': obj_type, 'count': len(objects)})

        if db_object_data:
            db_df = pd.DataFrame(db_object_data)
            db_summary = db_df.groupby('type')['count'].sum().reset_index()

            fig4 = px.bar(
                db_summary,
                x='type',
                y='count',
                title="Database Objects by Type",
                labels={'type': 'Object Type', 'count': 'Count'}
            )
            fig4.update_layout(height=400)
            charts_html += f'<div class="chart-container" id="db-objects-chart">{fig4.to_html(include_plotlyjs=False, div_id="db-objects-chart")}</div>'

        return charts_html

    def export_to_excel(self, output_file: str = "oracle_sql_analysis.xlsx") -> str:
        """Export analysis results to Excel"""
        if not self.metrics:
            raise ValueError("No metrics available. Run scan_directory first.")

        df = pd.DataFrame([asdict(m) for m in self.metrics])

        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            # Summary sheet
            summary_df = pd.DataFrame([self.summary_stats]).T
            summary_df.columns = ['Value']
            summary_df.to_excel(writer, sheet_name='Summary')

            # Detailed metrics
            df.to_excel(writer, sheet_name='File_Details', index=False)

            # Risk analysis
            risk_summary = df.groupby('risk_level').agg({
                'file_name': 'count',
                'code_lines': 'sum',
                'estimated_effort_hours': 'sum',
                'cyclomatic_complexity': 'mean'
            }).round(2)
            risk_summary.to_excel(writer, sheet_name='Risk_Analysis')

            # Database objects summary
            db_data = []
            for _, row in df.iterrows():
                if isinstance(row['database_objects'], dict):
                    for obj_type, objects in row['database_objects'].items():
                        if isinstance(objects, list):
                            for obj in objects:
                                db_data.append({
                                    'file_name': row['file_name'],
                                    'object_type': obj_type,
                                    'object_name': obj
                                })

            if db_data:
                db_df = pd.DataFrame(db_data)
                db_df.to_excel(writer, sheet_name='Database_Objects', index=False)

            # Oracle features summary
            feature_data = []
            for _, row in df.iterrows():
                if isinstance(row['oracle_features'], list):
                    for feature in row['oracle_features']:
                        feature_data.append({
                            'file_name': row['file_name'],
                            'feature': feature
                        })

            if feature_data:
                feature_df = pd.DataFrame(feature_data)
                feature_summary = feature_df.groupby('feature').size().reset_index(name='count')
                feature_summary.to_excel(writer, sheet_name='Oracle_Features', index=False)

        self.logger.info(f"Excel report generated: {output_file}")
        return output_file

    def print_summary(self) -> None:
        """Print colored summary to console"""
        if not self.summary_stats:
            print(f"{Fore.RED}No analysis results available{Style.RESET_ALL}")
            return

        print(f"\n{Fore.CYAN}{'='*60}")
        print(f"{Fore.CYAN}ORACLE SQL CODE COMPLEXITY ANALYSIS SUMMARY")
        print(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")

        print(f"\n{Fore.GREEN}üìä Overview:{Style.RESET_ALL}")
        print(f"   Total Files: {Fore.YELLOW}{self.summary_stats['total_files']}{Style.RESET_ALL}")
        print(f"   Total Lines of Code: {Fore.YELLOW}{self.summary_stats['total_code_lines']:,}{Style.RESET_ALL}")
        print(f"   Estimated Effort: {Fore.YELLOW}{self.summary_stats['total_estimated_hours']:.1f} hours{Style.RESET_ALL}")

        print(f"\n{Fore.GREEN}‚ö†Ô∏è  Risk Assessment:{Style.RESET_ALL}")
        print(f"   {Fore.RED}High Risk: {self.summary_stats['high_risk_files']} files{Style.RESET_ALL}")
        print(f"   {Fore.YELLOW}Medium Risk: {self.summary_stats['medium_risk_files']} files{Style.RESET_ALL}")
        print(f"   {Fore.GREEN}Low Risk: {self.summary_stats['low_risk_files']} files{Style.RESET_ALL}")

        print(f"\n{Fore.GREEN}üîß Database Objects:{Style.RESET_ALL}")
        print(f"   Procedures: {Fore.YELLOW}{self.summary_stats['total_procedures']}{Style.RESET_ALL}")
        print(f"   Functions: {Fore.YELLOW}{self.summary_stats['total_functions']}{Style.RESET_ALL}")
        print(f"   Triggers: {Fore.YELLOW}{self.summary_stats['total_triggers']}{Style.RESET_ALL}")
        print(f"   Packages: {Fore.YELLOW}{self.summary_stats['total_packages']}{Style.RESET_ALL}")

        print(f"\n{Fore.GREEN}üìà Key Metrics:{Style.RESET_ALL}")
        print(f"   Average Complexity: {Fore.YELLOW}{self.summary_stats['average_complexity']:.1f}{Style.RESET_ALL}")
        print(f"   Most Complex File: {Fore.YELLOW}{self.summary_stats['most_complex_file']}{Style.RESET_ALL}")
        print(f"   Largest File: {Fore.YELLOW}{self.summary_stats['largest_file']}{Style.RESET_ALL}")

        print(f"\n{Fore.GREEN}üìÅ File Types:{Style.RESET_ALL}")
        for file_type, count in self.summary_stats['file_types'].items():
            print(f"   {file_type}: {Fore.YELLOW}{count} files{Style.RESET_ALL}")

def main():
    """Main function to run the analyzer"""
    parser = argparse.ArgumentParser(description='Oracle SQL Code Complexity Analyzer')
    parser.add_argument('path', help='Path to Oracle SQL project directory')
    parser.add_argument('--config', default='sql_config.yaml', help='Configuration file path')
    parser.add_argument('--output', default='oracle_sql_analysis_report.html', help='Output HTML file')
    parser.add_argument('--excel', help='Output Excel file (optional)')
    parser.add_argument('--recursive', action='store_true', default=True, help='Scan subdirectories')
    parser.add_argument('--quiet', action='store_true', help='Suppress console output')

    args = parser.parse_args()

    try:
        # Initialize analyzer
        analyzer = OracleSQLAnalyzer(args.config)

        if not args.quiet:
            print(f"{Fore.CYAN}Starting Oracle SQL Code Analysis...{Style.RESET_ALL}")

        # Scan directory
        analyzer.scan_directory(args.path, args.recursive)

        # Print summary
        if not args.quiet:
            analyzer.print_summary()

        # Generate reports
        html_file = analyzer.generate_html_report(args.output)
        print(f"\n{Fore.GREEN}‚úÖ HTML report generated: {html_file}{Style.RESET_ALL}")

        if args.excel:
            excel_file = analyzer.export_to_excel(args.excel)
            print(f"{Fore.GREEN}‚úÖ Excel report generated: {excel_file}{Style.RESET_ALL}")

        print(f"\n{Fore.CYAN}Analysis complete!{Style.RESET_ALL}")

    except Exception as e:
        print(f"{Fore.RED}‚ùå Error: {str(e)}{Style.RESET_ALL}")
        return 1

    return 0

if __name__ == "__main__":
    exit(main())
